<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Introduction</title>
    <link>http://botcs.github.io/sam/</link>
    <description>Recent content on Introduction</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 19 Mar 2018 02:57:08 +0100</lastBuildDate>
    
	<atom:link href="http://botcs.github.io/sam/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Training Sam</title>
      <link>http://botcs.github.io/sam/projects/neural1/</link>
      <pubDate>Mon, 19 Mar 2018 02:57:08 +0100</pubDate>
      
      <guid>http://botcs.github.io/sam/projects/neural1/</guid>
      <description>HOW DOES A RECOGNITION SYSTEM WORK? If you are curious about core concepts and what should the Neural Network (a.k.a Sam&amp;rsquo;s brain) learn - take a look at my online slideshow which demonstrates completely ridiculous usage of the Parallax effect.</description>
    </item>
    
    <item>
      <title>Embedding Sam</title>
      <link>http://botcs.github.io/sam/projects/embedded/</link>
      <pubDate>Mon, 19 Mar 2018 02:45:19 +0100</pubDate>
      
      <guid>http://botcs.github.io/sam/projects/embedded/</guid>
      <description>This is the most tricky part. We have something that works with a GTX 1080 Ti&amp;hellip; fine&amp;hellip; what doesn&amp;rsquo;t work with a 1080 Ti? The true challenge is to find some computing unit that is small enough to align with the current design of the entrance system, while being able to compute a Convolutional Neural Networks responses (the brain of Sam).
By courtesy of Zsedrovits Tam√°s, we got a Jetson TX1 board to run Sam&amp;rsquo;s recognition software onboard.</description>
    </item>
    
    <item>
      <title>Connecting Sam</title>
      <link>http://botcs.github.io/sam/projects/listen/</link>
      <pubDate>Mon, 19 Mar 2018 03:07:16 +0100</pubDate>
      
      <guid>http://botcs.github.io/sam/projects/listen/</guid>
      <description>Currently the cam is recording in show-time, and Sam processes the recorded frames by selecting whether there are any face on them. If no recognizable face was found then to make room for more valuable memories &amp;ldquo;empty&amp;rdquo; frames gets removed automatically. The ID matching happens via matching a log file of the card readers.
To make this whole process smoother and less energy consuming the ID-face matching will occur instantaneously by making Sam listen on the card readers directly.</description>
    </item>
    
    <item>
      <title>About</title>
      <link>http://botcs.github.io/sam/about/</link>
      <pubDate>Mon, 19 Mar 2018 01:41:48 +0100</pubDate>
      
      <guid>http://botcs.github.io/sam/about/</guid>
      <description>Facebook is doing some fancy stuff, Google is doing some groundbreaking research. Why shouldn&amp;rsquo;t we join? All resources are publicly available to make a working face recognition system, and this case study is about implementing &amp;amp; deploying something that could make our everyday life easier a bit.
Purposes: The goal is a completely safe upgrade to our current security system that lets people who have signed up pass without their ID tag, using only their faces for identification.</description>
    </item>
    
  </channel>
</rss>