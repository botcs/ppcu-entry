{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "from utils.triplet_image_loader import TripletImageLoader\n",
    "from utils.openface import prepareOpenFace\n",
    "from tripletnet import Tripletnet\n",
    "from visdom import Visdom\n",
    "import numpy as np\n",
    "import dlib\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "    TripletImageLoader(\n",
    "        'name_photoPaths_train.csv', \n",
    "        transform=transforms.Compose([\n",
    "            transforms.Resize(96),\n",
    "            transforms.CenterCrop(96),\n",
    "            transforms.ToTensor(),\n",
    "        ]), \n",
    "        triplets_per_individual = 100\n",
    "    ),\n",
    "    batch_size=200, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.features = models.squeezenet1_1.features\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.Dropout(),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = nn.functional.adaptive_max_pool2d(x, 2)\n",
    "        batch_size = x.size(0)\n",
    "        x = x.view(batch_size, -1)\n",
    "        return self.embedding(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load('runs/TripletNet/model_best.pth.tar')['state_dict'])\n",
    "if torch.cuda.is_available():\n",
    "    net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = iter(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch to evaluation mode\n",
    "net.eval()\n",
    "anchor, positive, negative = next(test_iter)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    anchor, positive, negative = anchor.cuda(), positive.cuda(), negative.cuda()\n",
    "anchor = Variable(anchor, volatile=True)\n",
    "positive = Variable(positive, volatile=True)\n",
    "negative = Variable(negative, volatile=True)\n",
    "\n",
    "# compute output\n",
    "embedded_anchor = net(anchor)\n",
    "embedded_positive = net(positive)\n",
    "embedded_negative = net(negative)\n",
    "\n",
    "pdist = nn.PairwiseDistance(p=2)\n",
    "dist1 = pdist(embedded_anchor, embedded_positive)\n",
    "dist2 = pdist(embedded_anchor, embedded_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (a, p, n, d1, d2) in enumerate(zip(anchor, positive, negative, dist1, dist2)):\n",
    "    a_img = np.uint8(a.data.cpu().numpy()*255).transpose(1, 2, 0)\n",
    "    p_img = np.uint8(p.data.cpu().numpy()*255).transpose(1, 2, 0)\n",
    "    n_img = np.uint8(n.data.cpu().numpy()*255).transpose(1, 2, 0)\n",
    "    d1 = d1.data.cpu().tolist()[0]\n",
    "    d2 = d2.data.cpu().tolist()[0]\n",
    "    \n",
    "    if d1 < d2:\n",
    "        continue\n",
    "    print('EXAMPLE %03d' % i, 'CORRECT' if d1 < d2 else '!!! FAIL')\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(a_img)\n",
    "    plt.title('Distance: 0')\n",
    "    plt.subplot(132)\n",
    "    plt.imshow(p_img)\n",
    "    plt.title('Distance: %2.3f' % d1)\n",
    "    plt.subplot(133)\n",
    "    plt.imshow(n_img)\n",
    "    plt.title('Distance: %2.3f' % d2)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
